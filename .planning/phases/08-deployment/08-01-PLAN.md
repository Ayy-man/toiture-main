---
phase: 08-deployment
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/Dockerfile
  - backend/railway.json
  - backend/app/main.py
  - backend/app/config.py
  - backend/app/services/llm_reasoning.py
  - backend/app/services/pinecone_cbr.py
  - backend/app/routers/estimate.py
  - backend/app/routers/feedback.py
  - backend/app/routers/__init__.py
  - backend/app/schemas/__init__.py
  - backend/.env.example
  - frontend/vercel.json
  - frontend/.env.example
autonomous: true

must_haves:
  truths:
    - "Backend builds successfully in Docker container"
    - "Dockerfile uses CPU-only PyTorch (no CUDA bloat)"
    - "Health check path configured in railway.json"
    - "Python imports work for Railway deployment"
    - "Supabase settings available in config"
  artifacts:
    - path: "backend/Dockerfile"
      provides: "Docker build configuration for Railway"
      contains: "download.pytorch.org/whl/cpu"
    - path: "backend/railway.json"
      provides: "Railway deployment configuration"
      contains: "healthcheckPath"
    - path: "frontend/vercel.json"
      provides: "Vercel deployment hints"
      contains: "nextjs"
  key_links:
    - from: "backend/Dockerfile"
      to: "backend/app/main.py"
      via: "COPY command"
      pattern: "COPY app/"
    - from: "backend/railway.json"
      to: "backend/Dockerfile"
      via: "DOCKERFILE builder"
      pattern: "DOCKERFILE"
---

<objective>
Create deployment configuration files for Railway (backend) and Vercel (frontend).

Purpose: Prepare the codebase for production deployment with optimized Docker builds and platform-specific configuration.

Output: Dockerfile, railway.json, vercel.json, and updated config files ready for deployment.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-deployment/08-RESEARCH.md
@backend/app/config.py
@backend/app/main.py
@backend/requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Backend Deployment Files</name>
  <files>
    backend/Dockerfile
    backend/railway.json
    backend/app/main.py
    backend/app/config.py
    backend/app/services/llm_reasoning.py
    backend/app/services/pinecone_cbr.py
    backend/app/routers/estimate.py
    backend/app/routers/feedback.py
    backend/app/routers/__init__.py
    backend/app/schemas/__init__.py
    backend/.env.example
  </files>
  <action>
1. Create `backend/Dockerfile`:
   - Base: `python:3.11-slim`
   - WORKDIR: `/app`
   - Set `PYTHONDONTWRITEBYTECODE=1` and `PYTHONUNBUFFERED=1`
   - Install CPU-only PyTorch FIRST: `pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cpu`
   - Copy and install requirements.txt
   - Copy app/ directory
   - CMD: `["sh", "-c", "fastapi run app/main.py --host 0.0.0.0 --port ${PORT:-8000}"]`

2. Create `backend/railway.json`:
   - schema: "https://railway.com/railway.schema.json"
   - build.builder: "DOCKERFILE"
   - build.dockerfilePath: "./Dockerfile"
   - deploy.healthcheckPath: "/health"
   - deploy.healthcheckTimeout: 300 (5 minutes for ML model loading)
   - deploy.restartPolicyType: "ON_FAILURE"
   - deploy.restartPolicyMaxRetries: 3

3. Fix ALL `backend/app/**/*.py` imports:
   - Change `from backend.app.*` to `from app.*` (Railway runs from backend/ directory)
   - Files to update:
     - backend/app/main.py
     - backend/app/services/llm_reasoning.py
     - backend/app/services/pinecone_cbr.py
     - backend/app/routers/estimate.py
     - backend/app/routers/feedback.py
     - backend/app/routers/__init__.py
     - backend/app/schemas/__init__.py

4. Add Supabase settings to `backend/app/config.py`:
   - supabase_url: str = ""
   - supabase_service_key: str = ""
   (These are already used by supabase_client.py but loaded directly from env, better to centralize)

5. Update `backend/.env.example` with all required variables:
   - CORS_ORIGINS, MODEL_DIR
   - PINECONE_API_KEY, PINECONE_INDEX_HOST
   - OPENROUTER_API_KEY, OPENROUTER_MODEL
   - SUPABASE_URL, SUPABASE_SERVICE_KEY
  </action>
  <verify>
  ```bash
  # Verify Dockerfile syntax
  docker build -t toiturelv-test -f backend/Dockerfile backend/ --dry-run 2>&1 | head -20 || echo "Dry-run not supported, check file exists"

  # Check files exist
  ls -la backend/Dockerfile backend/railway.json

  # Verify ALL imports are fixed - this should return empty
  grep -r 'from backend\.app\.' backend/app/

  # Verify config has supabase settings
  grep "supabase" backend/app/config.py
  ```
  </verify>
  <done>
    - Dockerfile exists with CPU-only PyTorch installation
    - railway.json exists with health check configured
    - ALL .py files use `from app.*` pattern (grep returns empty)
    - config.py includes supabase settings
    - .env.example documents all required variables
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Frontend Deployment Files</name>
  <files>
    frontend/vercel.json
    frontend/.env.example
  </files>
  <action>
1. Create `frontend/vercel.json`:
   - schema: "https://openapi.vercel.sh/vercel.json"
   - framework: "nextjs"
   - installCommand: "pnpm install"
   - buildCommand: "pnpm build"

2. Create `frontend/.env.example` documenting required variables:
   - NEXT_PUBLIC_API_URL (Railway backend URL)
   - NEXT_PUBLIC_SUPABASE_URL
   - NEXT_PUBLIC_SUPABASE_ANON_KEY
   - IRON_SESSION_SECRET (32+ character random string)
   - APP_PASSWORD (shared team password)

Include comments explaining each variable's purpose and where to get values.
  </action>
  <verify>
  ```bash
  # Check files exist
  ls -la frontend/vercel.json frontend/.env.example

  # Verify vercel.json is valid JSON
  cat frontend/vercel.json | python3 -m json.tool > /dev/null && echo "Valid JSON"
  ```
  </verify>
  <done>
    - vercel.json exists with Next.js framework specified
    - .env.example documents all NEXT_PUBLIC_* and server-side env vars
  </done>
</task>

<task type="auto">
  <name>Task 3: Local Docker Build Test</name>
  <files>
    backend/Dockerfile
  </files>
  <action>
Build the Docker image locally to verify it works before deployment.

1. Run: `docker build -t toiturelv-backend -f backend/Dockerfile backend/`
   - Expect: Build completes successfully (may take 5-10 minutes first time due to PyTorch)

2. If build fails:
   - Check for missing requirements in requirements.txt
   - Verify COPY paths match directory structure
   - Check for syntax errors in Dockerfile

Note: We don't run the container (would need env vars and model files), just verify build works.
  </action>
  <verify>
  ```bash
  # Build and check exit code
  docker build -t toiturelv-backend -f backend/Dockerfile backend/
  docker images | grep toiturelv-backend
  ```
  </verify>
  <done>
    - Docker image builds successfully
    - Image size reasonable (under 3GB with CPU-only PyTorch)
  </done>
</task>

</tasks>

<verification>
- [ ] backend/Dockerfile exists and uses CPU-only PyTorch
- [ ] backend/railway.json exists with health check configured
- [ ] ALL backend/app/**/*.py imports work standalone (not from backend.*)
- [ ] frontend/vercel.json exists with Next.js config
- [ ] Docker build completes successfully
- [ ] All .env.example files document required variables
</verification>

<success_criteria>
1. Docker image builds in under 15 minutes
2. All config files are valid (JSON parses, no syntax errors)
3. Imports are compatible with Railway deployment structure (grep -r 'from backend\.app\.' returns empty)
4. Documentation exists for all required environment variables
</success_criteria>

<output>
After completion, create `.planning/phases/08-deployment/08-01-SUMMARY.md`
</output>
