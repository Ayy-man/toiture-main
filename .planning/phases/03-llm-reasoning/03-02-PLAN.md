---
phase: 03-llm-reasoning
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - backend/app/main.py
  - backend/app/schemas/estimate.py
  - backend/app/routers/estimate.py
  - backend/tests/test_estimate.py
autonomous: true

must_haves:
  truths:
    - "LLM client initializes at app startup"
    - "LLM client closes at app shutdown"
    - "/estimate response includes reasoning field"
    - "Reasoning is None (not error) when LLM fails"
    - "Existing estimate tests still pass"
  artifacts:
    - path: "backend/app/main.py"
      provides: "LLM lifecycle integration"
      contains: "init_llm_client"
    - path: "backend/app/schemas/estimate.py"
      provides: "reasoning field in response"
      contains: "reasoning: Optional[str]"
    - path: "backend/app/routers/estimate.py"
      provides: "reasoning generation in endpoint"
      contains: "generate_reasoning"
  key_links:
    - from: "backend/app/main.py"
      to: "backend/app/services/llm_reasoning.py"
      via: "import and lifespan calls"
      pattern: "init_llm_client|close_llm_client"
    - from: "backend/app/routers/estimate.py"
      to: "backend/app/services/llm_reasoning.py"
      via: "generate_reasoning call"
      pattern: "generate_reasoning\\("
---

<objective>
Integrate LLM reasoning into the estimate endpoint with proper lifecycle management and graceful degradation.

Purpose: Complete the LLM integration so /estimate responses include human-readable reasoning that references similar cases and explains confidence.

Output: Updated main.py with LLM lifecycle, updated schemas with reasoning field, updated estimate router with reasoning generation, updated tests to verify integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-llm-reasoning/03-RESEARCH.md
@.planning/phases/03-llm-reasoning/03-01-SUMMARY.md
@backend/app/main.py
@backend/app/schemas/estimate.py
@backend/app/routers/estimate.py
@backend/tests/test_estimate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add reasoning field to response schema</name>
  <files>backend/app/schemas/estimate.py</files>
  <action>
Update EstimateResponse class in backend/app/schemas/estimate.py:

1. Add import: `from typing import List, Literal, Optional` (Optional may already be there)

2. Add reasoning field to EstimateResponse:
   ```python
   reasoning: Optional[str] = None  # LLM-generated explanation
   ```

Field is Optional with None default so endpoint works even when LLM is unavailable.
  </action>
  <verify>
Run: `python -c "from backend.app.schemas.estimate import EstimateResponse; print(EstimateResponse.model_fields.keys())"`
Check: Output includes 'reasoning' in field keys
  </verify>
  <done>
EstimateResponse has reasoning: Optional[str] = None field. Schema validates with or without reasoning.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire LLM lifecycle into main.py</name>
  <files>backend/app/main.py</files>
  <action>
Update backend/app/main.py lifespan to init/close LLM client:

1. Add import:
   ```python
   from backend.app.services.llm_reasoning import init_llm_client, close_llm_client
   ```

2. Update lifespan function - add after init_pinecone():
   ```python
   init_llm_client()  # OpenRouter LLM client
   ```

3. Update lifespan shutdown - add before close_pinecone():
   ```python
   close_llm_client()
   ```

Order matters: init last thing that depends on config, close in reverse order.
Final startup order: load_models -> load_embedding_model -> init_pinecone -> init_llm_client
Final shutdown order: close_llm_client -> close_pinecone -> unload_embedding_model -> unload_models
  </action>
  <verify>
Run: `python -c "from backend.app.main import app; print('App imports OK')"`
Check: No import errors
  </verify>
  <done>
main.py lifespan calls init_llm_client() on startup and close_llm_client() on shutdown. Order is correct.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate reasoning into estimate endpoint</name>
  <files>backend/app/routers/estimate.py</files>
  <action>
Update backend/app/routers/estimate.py to generate reasoning:

1. Add import:
   ```python
   from backend.app.services.llm_reasoning import generate_reasoning
   ```

2. In create_estimate(), after getting similar_cases, add reasoning generation:
   ```python
   # Generate LLM reasoning (graceful degradation)
   try:
       reasoning = generate_reasoning(
           estimate=result["estimate"],
           confidence=result["confidence"],
           sqft=request.sqft,
           category=request.category,
           similar_cases=[
               {
                   "category": c.category,
                   "sqft": c.sqft,
                   "total": c.total,
                   "per_sqft": c.per_sqft,
                   "similarity": c.similarity,
                   "year": c.year,
               }
               for c in similar_cases
           ],
       )
   except Exception as e:
       logger.warning(f"LLM reasoning failed: {e}")
       reasoning = None
   ```

3. Update return statement to include reasoning:
   ```python
   return EstimateResponse(
       estimate=result["estimate"],
       range_low=result["range_low"],
       range_high=result["range_high"],
       confidence=result["confidence"],
       model=result["model"],
       similar_cases=similar_cases,
       reasoning=reasoning,  # NEW
   )
   ```

Key: Convert SimilarCase objects to dicts for generate_reasoning. Catch ALL exceptions for graceful degradation.
  </action>
  <verify>
Run: `python -c "from backend.app.routers.estimate import router; print('Router imports OK')"`
Check: No import errors
  </verify>
  <done>
estimate.py imports generate_reasoning, calls it with proper arguments, handles exceptions gracefully, includes reasoning in response.
  </done>
</task>

<task type="auto">
  <name>Task 4: Run existing tests and add reasoning test</name>
  <files>backend/tests/test_estimate.py</files>
  <action>
1. First, run existing tests to ensure nothing broke:
   ```bash
   cd /Users/aymanbaig/Desktop/Toiture-P1 && python -m pytest backend/tests/ -v
   ```

2. Add test for reasoning field in test_estimate.py:
   ```python
   def test_estimate_response_has_reasoning_field(client):
       """Test that estimate response includes reasoning field."""
       response = client.post(
           "/estimate",
           json={
               "sqft": 2500,
               "category": "Bardeaux",
               "material_lines": 5,
               "labor_lines": 2,
               "has_subs": 0,
               "complexity": 10,
           },
       )
       assert response.status_code == 200
       data = response.json()
       # reasoning field exists (may be None if no API key or string if working)
       assert "reasoning" in data
       # If reasoning is present, it should be a string
       if data["reasoning"] is not None:
           assert isinstance(data["reasoning"], str)
           assert len(data["reasoning"]) > 0
   ```

Note: Test checks field exists but allows None (graceful degradation when no API key in test env).
  </action>
  <verify>
Run: `cd /Users/aymanbaig/Desktop/Toiture-P1 && python -m pytest backend/tests/ -v`
Check: All tests pass including new reasoning test
  </verify>
  <done>
All existing tests pass. New test verifies reasoning field exists in response (allows None for graceful degradation).
  </done>
</task>

</tasks>

<verification>
1. `python -c "from backend.app.main import app"` - no import errors
2. `python -c "from backend.app.routers.estimate import router"` - no import errors
3. `python -m pytest backend/tests/ -v` - all tests pass
4. EstimateResponse schema includes reasoning field
5. If OPENROUTER_API_KEY is set in .env, manual test returns reasoning string
6. If OPENROUTER_API_KEY is not set, endpoint still works with reasoning=None
</verification>

<success_criteria>
- main.py lifespan initializes and closes LLM client
- EstimateResponse has reasoning: Optional[str] field
- estimate.py calls generate_reasoning and handles failures gracefully
- All existing tests pass (9 tests)
- New test verifies reasoning field exists in response
- Endpoint works with or without OPENROUTER_API_KEY (graceful degradation)
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-reasoning/03-02-SUMMARY.md`
</output>
