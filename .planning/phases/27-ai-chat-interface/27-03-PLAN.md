---
phase: 27-ai-chat-interface
plan: 03
type: execute
wave: 2
depends_on: ["27-01", "27-02"]
files_modified:
  - frontend/src/lib/api/chat.ts
  - frontend/src/components/chat/chat-container.tsx
  - frontend/src/components/chat/quote-summary-card.tsx
  - frontend/src/types/chat.ts
autonomous: true

must_haves:
  truths:
    - "Frontend sends messages to POST /chat/message and displays LLM-generated replies"
    - "Extracted fields update in real-time as user provides job details"
    - "3-tier quote card renders inline in chat when quote is generated"
    - "User can select a tier and create a submission directly from the chat"
    - "Suggestion pills reflect server-returned context-aware suggestions"
  artifacts:
    - path: "frontend/src/lib/api/chat.ts"
      provides: "API client functions for chat endpoint"
      contains: "sendChatMessage"
    - path: "frontend/src/components/chat/quote-summary-card.tsx"
      provides: "Embedded 3-tier quote card with tier selection and submission button"
      contains: "QuoteSummaryCard"
    - path: "frontend/src/types/chat.ts"
      provides: "TypeScript types for chat API request/response"
      contains: "ChatMessageResponse"
  key_links:
    - from: "frontend/src/components/chat/chat-container.tsx"
      to: "frontend/src/lib/api/chat.ts"
      via: "sendChatMessage() call in handleSend"
      pattern: "sendChatMessage"
    - from: "frontend/src/components/chat/chat-container.tsx"
      to: "frontend/src/components/chat/quote-summary-card.tsx"
      via: "renders QuoteSummaryCard when quote exists in response"
      pattern: "QuoteSummaryCard"
    - from: "frontend/src/components/chat/quote-summary-card.tsx"
      to: "frontend/src/lib/api/submissions.ts"
      via: "createSubmission() for 'Create Submission' button"
      pattern: "createSubmission"
---

<objective>
Wire the frontend chat UI to the backend POST /chat/message endpoint, add the embedded QuoteSummaryCard component for displaying generated quotes inline in the chat, and integrate submission creation. This is the integration plan that connects Plans 01 and 02.

Purpose: Make the chat fully functional end-to-end — Steven types a job description, sees extracted fields, gets a quote, and can create a submission all within the chat interface.

Output: Fully integrated chat that communicates with the backend, displays real LLM responses, shows 3-tier quotes inline, and creates submissions.
</objective>

<execution_context>
@/Users/aymanbaig/.claude/get-shit-done/workflows/execute-plan.md
@/Users/aymanbaig/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/27-ai-chat-interface/DESIGN.md
@.planning/phases/27-ai-chat-interface/27-01-SUMMARY.md
@.planning/phases/27-ai-chat-interface/27-02-SUMMARY.md
@frontend/src/lib/api/submissions.ts
@frontend/src/lib/api/hybrid-quote.ts
@frontend/src/types/submission.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Chat TypeScript types and API client</name>
  <files>
    frontend/src/types/chat.ts
    frontend/src/lib/api/chat.ts
  </files>
  <action>
**1. frontend/src/types/chat.ts** — TypeScript types for chat:

Define types that mirror the backend Pydantic schemas:

```typescript
export interface ChatMessage {
  id: string;           // UUID generated client-side
  role: "user" | "assistant";
  content: string;
  timestamp: string;    // ISO timestamp
  quote?: ChatQuoteData; // Present when quote is embedded in this message
}

export interface ChatMessageRequest {
  session_id: string;
  message: string;
  language?: string;    // "fr" | "en"
}

export interface ChatMessageResponse {
  reply: string;
  extracted_fields: Record<string, unknown>;
  suggestions: string[];
  quote: HybridQuoteResponseData | null;
  needs_clarification: boolean;
  session_state: string;  // "greeting" | "extracting" | "clarifying" | "ready" | "generated"
}

// Reuse the existing HybridQuoteResponse type shape but as a simple interface
// to avoid import issues (the full type is in types/hybrid-quote or inlined from API response)
export interface HybridQuoteResponseData {
  work_items: Array<{ name: string; labor_hours: number; source: string }>;
  materials: Array<{ material_id: number; quantity: number; unit_price: number; total: number }>;
  total_labor_hours: number;
  total_materials_cost: number;
  total_price: number;
  overall_confidence: number;
  reasoning: string;
  pricing_tiers: Array<{
    tier: "Basic" | "Standard" | "Premium";
    total_price: number;
    materials_cost: number;
    labor_cost: number;
    description: string;
  }>;
  needs_review: boolean;
  processing_time_ms: number;
}

export interface ChatQuoteData {
  quote: HybridQuoteResponseData;
  selectedTier?: "Basic" | "Standard" | "Premium";
}

export interface ChatSessionState {
  sessionId: string;
  messages: ChatMessage[];
  extractedFields: Record<string, unknown>;
  sessionState: string;
  suggestions: string[];
}
```

**2. frontend/src/lib/api/chat.ts** — API client for chat endpoint:

Follow the exact pattern of `frontend/src/lib/api/submissions.ts`:

```typescript
const API_URL = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8000";
```

Functions:

- `sendChatMessage(sessionId: string, message: string, language?: string): Promise<ChatMessageResponse>`:
  - POST to `${API_URL}/chat/message`
  - Body: `{ session_id: sessionId, message, language: language || "fr" }`
  - Headers: `{ "Content-Type": "application/json" }`
  - Parse response as ChatMessageResponse
  - On error: throw Error with detail message (same pattern as submissions.ts)

- `resetChatSession(sessionId: string): Promise<void>`:
  - POST to `${API_URL}/chat/reset?session_id=${sessionId}`
  - No body needed

- `getChatSession(sessionId: string): Promise<ChatSessionState | null>`:
  - GET `${API_URL}/chat/session/${sessionId}`
  - Returns session state or null if 404

- `generateSessionId(): string`:
  - Returns `crypto.randomUUID()` (browser API, no dependency needed)
  - Fallback for older browsers: `Date.now().toString(36) + Math.random().toString(36).slice(2)`
  </action>
  <verify>
    Run: `cd frontend && npx tsc --noEmit --pretty 2>&1 | grep -i "chat" | head -10` — Should show no type errors in chat files.
    Verify files exist: `ls frontend/src/types/chat.ts frontend/src/lib/api/chat.ts`
  </verify>
  <done>
    TypeScript types mirror backend schemas. API client provides sendChatMessage, resetChatSession, getChatSession, and generateSessionId functions following the established fetch-based pattern.
  </done>
</task>

<task type="auto">
  <name>Task 2: QuoteSummaryCard and ChatContainer API integration</name>
  <files>
    frontend/src/components/chat/quote-summary-card.tsx
    frontend/src/components/chat/chat-container.tsx
  </files>
  <action>
**1. frontend/src/components/chat/quote-summary-card.tsx** — Embedded quote card:
```
"use client";
```

Props:
- `quote: HybridQuoteResponseData` — The quote data from API
- `onSelectTier: (tier: "Basic" | "Standard" | "Premium") => void`
- `onCreateSubmission: (tier: "Basic" | "Standard" | "Premium") => void`
- `selectedTier?: "Basic" | "Standard" | "Premium"` — Currently selected tier
- `isCreatingSubmission?: boolean` — Loading state for submission creation

Component structure:
- Renders inside a chat message bubble (assistant-styled, but full-width)
- Uses shadcn Card component as wrapper
- Card header: "Devis genere" / "Quote Generated" with confidence badge
- Three pricing tier cards in a responsive grid (1 col on mobile, 3 on desktop):
  - Each tier: Card with tier name (Basic/Standard/Premium), total price prominently displayed, materials/labor breakdown, description text
  - Selected tier has ring-2 ring-primary border highlight
  - Click to select: `onSelectTier(tier.tier)`
  - Use fr-CA locale for price formatting: `new Intl.NumberFormat('fr-CA', { style: 'currency', currency: 'CAD' }).format(price)`
- Below tiers: "Create Submission" button (shadcn Button, primary variant, full-width on mobile)
  - Only enabled when a tier is selected
  - Shows loading spinner when isCreatingSubmission=true
  - Calls `onCreateSubmission(selectedTier!)` on click
- Small confidence indicator at bottom: colored dot (green >0.7, yellow >0.5, red <0.5) + percentage
- Use useLanguage() for all text labels (t.chat.selectTier, t.chat.createSubmission, etc.)

**2. frontend/src/components/chat/chat-container.tsx** — Replace mock behavior with real API:

Update the ChatContainer component (created in Plan 02) to use real API calls:

State changes:
- Add `sessionId` state initialized with `generateSessionId()` from api/chat.ts
- Add `extractedFields` state: `Record<string, unknown>`
- Add `currentQuote` state: `HybridQuoteResponseData | null`
- Add `selectedTier` state: `"Basic" | "Standard" | "Premium" | undefined`
- Add `isCreatingSubmission` state: boolean

Replace handleSend logic:
1. Add user message to local messages array (optimistic)
2. Set isLoading=true, clear suggestions
3. Call `sendChatMessage(sessionId, messageText, locale)` from api/chat.ts
4. On success:
   - Add assistant reply to messages
   - Update extractedFields from response.extracted_fields
   - Update suggestions from response.suggestions
   - If response.quote exists, add a special "quote" message type that renders QuoteSummaryCard
   - Update sessionState from response.session_state
5. On error:
   - Add error message as assistant reply: "An error occurred. Please try again." (bilingual)
   - Keep isLoading=false, restore previous suggestions
6. Set isLoading=false

Replace handleNewChat:
1. Call `resetChatSession(sessionId)`
2. Generate new sessionId
3. Clear all local state (messages, extractedFields, quote, suggestions)
4. Add greeting message

Add handleSelectTier:
- Update selectedTier state

Add handleCreateSubmission:
- Set isCreatingSubmission=true
- Build SubmissionCreatePayload from extractedFields + selected tier:
  ```typescript
  {
    quote_request: extractedFields as HybridQuoteRequest,
    quote_response: currentQuote,
    selected_tier: selectedTier,
    status: "draft",
    client_name: extractedFields.client_name || `Chat Quote ${new Date().toLocaleDateString('fr-CA')}`,
    notes: `Created from Cortex Chat session ${sessionId}`,
  }
  ```
- Call `createSubmission(payload)` from lib/api/submissions.ts
- On success: Add confirmation message to chat, show toast notification (use sonner toast if available, or just message)
- On error: Add error message to chat
- Set isCreatingSubmission=false

Handle QuoteSummaryCard rendering in message list:
- Messages now have optional `quote` field
- When rendering messages, check if message has quote data
- If yes, render `<QuoteSummaryCard />` instead of regular `<ChatMessage />`

Add extracted fields display:
- Small collapsible section (using shadcn Collapsible) below the header showing currently extracted fields
- Shows fields as key:value pairs in a compact format
- Only visible when extractedFields has entries
- Toggle with a small "Show extracted fields" / "Masquer les champs" button
  </action>
  <verify>
    Run: `cd frontend && npx tsc --noEmit --pretty 2>&1 | grep -c "error"` — Should show 0 errors (or only pre-existing ones).
    Verify QuoteSummaryCard: `ls frontend/src/components/chat/quote-summary-card.tsx` — File exists.
    Verify API import: `grep "sendChatMessage" frontend/src/components/chat/chat-container.tsx` — Import exists.
    Verify submission import: `grep "createSubmission" frontend/src/components/chat/quote-summary-card.tsx frontend/src/components/chat/chat-container.tsx` — Import exists in at least one file.
  </verify>
  <done>
    QuoteSummaryCard renders 3-tier pricing cards with selection and submission creation. ChatContainer is fully wired to POST /chat/message endpoint. Messages come from real LLM. Quote displays inline when generated. Submissions can be created directly from chat. Extracted fields are visible in collapsible panel.
  </done>
</task>

</tasks>

<verification>
1. Type "1200 pi2 bardeaux pente raide" in chat — LLM responds with extracted fields and natural language
2. After providing enough info, "ready" state triggers and suggestions include "Generate quote"
3. Clicking "Generate quote" shows typing indicator then displays QuoteSummaryCard inline
4. QuoteSummaryCard shows 3 tiers with prices in CAD format
5. Can select a tier (card gets highlighted border)
6. "Create Submission" button creates a submission and shows confirmation
7. Extracted fields collapsible shows accumulated field values
8. Error states handled gracefully (network error, LLM timeout)
9. Suggestions update after each response based on server context
</verification>

<success_criteria>
- End-to-end flow works: type description -> get quote -> create submission
- API calls follow the established fetch pattern from submissions.ts
- Quote card displays all 3 tiers with proper CAD formatting
- Submission creation integrates with existing submissions API
- All user-facing text uses i18n keys from FR/EN translation files
</success_criteria>

<output>
After completion, create `.planning/phases/27-ai-chat-interface/27-03-SUMMARY.md`
</output>
