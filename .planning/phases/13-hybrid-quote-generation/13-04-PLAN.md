---
phase: 13-hybrid-quote-generation
plan: 04
type: execute
wave: 4
depends_on: ["13-01", "13-02", "13-03"]
files_modified:
  - backend/app/routers/estimate.py
autonomous: true

must_haves:
  truths:
    - "POST /estimate/hybrid endpoint accepts HybridQuoteRequest and returns HybridQuoteResponse"
    - "Service call detection routes labor-only jobs to separate flow"
    - "Response time is tracked and logged for <5s SLA"
  artifacts:
    - path: "backend/app/routers/estimate.py"
      provides: "POST /estimate/hybrid endpoint"
      contains: "/estimate/hybrid"
  key_links:
    - from: "backend/app/routers/estimate.py"
      to: "backend/app/services/hybrid_quote.py"
      via: "generate_hybrid_quote import"
      pattern: "from app.services.hybrid_quote import"
---

<objective>
Create the POST /estimate/hybrid API endpoint with service call detection.

Purpose: This plan wires the hybrid quote orchestrator into the FastAPI application, making it available as an HTTP endpoint. The endpoint includes service call detection to route labor-only jobs appropriately.

Note: Uses existing OpenRouter LLM client (already initialized in app lifespan). No new API keys or config changes needed.

Output: Functional /estimate/hybrid endpoint
</objective>

<execution_context>
@/Users/aymanbaig/.claude/get-shit-done/workflows/execute-plan.md
@/Users/aymanbaig/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-hybrid-quote-generation/13-CONTEXT.md
@.planning/phases/13-hybrid-quote-generation/13-RESEARCH.md
@.planning/phases/13-hybrid-quote-generation/13-01-SUMMARY.md
@.planning/phases/13-hybrid-quote-generation/13-02-SUMMARY.md
@.planning/phases/13-hybrid-quote-generation/13-03-SUMMARY.md

# Files to modify
@backend/app/routers/estimate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add POST /estimate/hybrid endpoint</name>
  <files>backend/app/routers/estimate.py</files>
  <action>
Add the hybrid quote endpoint to the estimate router:

1. Add imports at top of file (these are shared with rest of file):
```python
from app.schemas.hybrid_quote import HybridQuoteRequest, HybridQuoteResponse, PricingTier
from app.services.hybrid_quote import generate_hybrid_quote
```

2. Add the endpoint after existing /estimate/full endpoint:
```python
@router.post("/estimate/hybrid", response_model=HybridQuoteResponse)
async def create_hybrid_estimate(request: HybridQuoteRequest):
    """Generate full hybrid quote using CBR + ML + LLM merger.

    This endpoint:
    1. Runs CBR (similar case retrieval) and ML (material prediction) in parallel
    2. Merges results using LLM with structured outputs
    3. Generates three-tier pricing (Basic/Standard/Premium)
    4. Returns confidence score and review flag

    Service calls (labor-only jobs) are detected and handled separately.

    Response time target: <5 seconds
    """
    # Service call detection: skip materials pipeline for labor-only jobs
    is_service_call = (
        request.material_lines == 0 or
        request.sqft < 100
    )

    if is_service_call:
        logger.info(f"Service call detected (sqft={request.sqft}, material_lines={request.material_lines})")
        # For service calls, use simple price prediction only
        try:
            price_result = predict(
                sqft=request.sqft,
                category=request.category,
                material_lines=request.material_lines,
                labor_lines=request.labor_lines,
                has_subs=1 if request.has_subs else 0,
                complexity=request.complexity_aggregate,
            )

            # Service call response: labor only, no materials
            # Note: PricingTier imported at top of file with other hybrid_quote imports
            return HybridQuoteResponse(
                work_items=[],
                materials=[],
                total_labor_hours=request.labor_lines * 2.0,  # Rough estimate
                total_materials_cost=0,
                total_price=price_result["estimate"],
                overall_confidence=0.6,  # Service calls are straightforward
                reasoning="Service call detected. Labor-only estimate based on ML prediction.",
                pricing_tiers=[
                    PricingTier(
                        tier="Basic",
                        total_price=round(price_result["estimate"] * 0.9, 2),
                        materials_cost=0,
                        labor_cost=round(price_result["estimate"] * 0.9, 2),
                        description="Standard service call"
                    ),
                    PricingTier(
                        tier="Standard",
                        total_price=round(price_result["estimate"], 2),
                        materials_cost=0,
                        labor_cost=round(price_result["estimate"], 2),
                        description="Service call with inspection"
                    ),
                    PricingTier(
                        tier="Premium",
                        total_price=round(price_result["estimate"] * 1.2, 2),
                        materials_cost=0,
                        labor_cost=round(price_result["estimate"] * 1.2, 2),
                        description="Emergency/rush service call"
                    ),
                ],
                needs_review=False,  # Service calls are low complexity
                cbr_cases_used=0,
                ml_confidence=price_result["confidence"],
                processing_time_ms=50,  # Fast path
            )
        except Exception as e:
            logger.error(f"Service call estimate error: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    # Normal path: full hybrid quote generation
    try:
        response = await generate_hybrid_quote(request)
        return response
    except RuntimeError as e:
        # Both CBR and ML failed
        logger.error(f"Hybrid quote failed: {e}")
        raise HTTPException(status_code=503, detail=str(e))
    except Exception as e:
        logger.error(f"Hybrid quote error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

Key implementation details:
- Service call detection: material_lines == 0 OR sqft < 100
- Service calls skip the full hybrid pipeline (fast path)
- Normal jobs use async generate_hybrid_quote()
- 503 returned when both CBR and ML fail
- 500 returned for other errors
- All schema imports (HybridQuoteRequest, HybridQuoteResponse, PricingTier) are at top of file - no inline imports
</action>
  <verify>
Check endpoint is defined:
```bash
cd /Users/aymanbaig/Desktop/Toiture-P1/backend && python -c "
from app.main import app
routes = [r.path for r in app.routes if hasattr(r, 'path')]
print('Routes:', routes)
assert '/estimate/hybrid' in routes, 'Missing /estimate/hybrid route'
print('/estimate/hybrid endpoint registered!')
"
```
</verify>
  <done>
- POST /estimate/hybrid endpoint accepts HybridQuoteRequest
- Service call detection routes labor-only jobs to fast path
- Normal jobs use full hybrid quote generation
- Appropriate error codes: 503 for total failure, 500 for other errors
- All imports consolidated at top of file (no redundant inline imports)
</done>
</task>

</tasks>

<verification>
1. /estimate/hybrid endpoint is registered in app routes
2. Service call detection works (material_lines=0 or sqft<100)
3. App starts without errors (uses existing OpenRouter client)
</verification>

<success_criteria>
- POST /estimate/hybrid endpoint exists and accepts HybridQuoteRequest
- Service calls (sqft < 100 or material_lines = 0) use fast path
- Uses existing OpenRouter LLM client (no new dependencies)
- App starts successfully
</success_criteria>

<output>
After completion, create `.planning/phases/13-hybrid-quote-generation/13-04-SUMMARY.md`
</output>
