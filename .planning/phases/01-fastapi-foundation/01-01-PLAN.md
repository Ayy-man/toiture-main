---
phase: 01-fastapi-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/__init__.py
  - backend/app/main.py
  - backend/app/config.py
  - backend/app/services/__init__.py
  - backend/app/services/predictor.py
  - backend/app/models/.gitkeep
  - backend/requirements.txt
  - backend/.env.example
autonomous: true

must_haves:
  truths:
    - "FastAPI app starts without errors"
    - "ML models load at startup"
    - "CORS allows localhost:3000"
  artifacts:
    - path: "backend/app/main.py"
      provides: "FastAPI app with lifespan and CORS"
      exports: ["app"]
    - path: "backend/app/services/predictor.py"
      provides: "ML model loading and prediction"
      exports: ["load_models", "unload_models", "predict"]
    - path: "backend/requirements.txt"
      provides: "Python dependencies"
      contains: "fastapi"
  key_links:
    - from: "backend/app/main.py"
      to: "backend/app/services/predictor.py"
      via: "lifespan context manager"
      pattern: "load_models\\(\\)"
---

<objective>
Create the FastAPI backend structure with ML model loading and CORS configuration.

Purpose: Establish the foundation for the estimate API - app structure, model loading at startup, and cross-origin configuration.

Output: Working FastAPI app that starts, loads models, and has CORS configured for frontend.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-fastapi-foundation/01-RESEARCH.md

# Existing prediction logic to adapt
@cortex-data/predict_final.py
@cortex-data/cortex_config_v3.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backend directory structure and dependencies</name>
  <files>
    backend/app/__init__.py
    backend/app/services/__init__.py
    backend/app/routers/__init__.py
    backend/app/schemas/__init__.py
    backend/app/models/.gitkeep
    backend/requirements.txt
    backend/.env.example
  </files>
  <action>
Create the backend directory structure following file-type organization:

```
backend/
├── app/
│   ├── __init__.py         # Empty
│   ├── routers/
│   │   └── __init__.py     # Empty
│   ├── schemas/
│   │   └── __init__.py     # Empty
│   ├── services/
│   │   └── __init__.py     # Empty
│   └── models/
│       └── .gitkeep        # Placeholder for ML model files
├── requirements.txt
└── .env.example
```

requirements.txt content:
```
fastapi[standard]>=0.128.0
pydantic>=2.7.0
pydantic-settings>=2.0.0
joblib>=1.3.0
numpy>=1.26.0
scikit-learn>=1.4.0
```

.env.example content:
```
CORS_ORIGINS=["http://localhost:3000"]
MODEL_DIR=app/models
```
  </action>
  <verify>
    ls -la backend/app/ shows all directories created
    cat backend/requirements.txt shows dependencies
  </verify>
  <done>Backend directory structure exists with requirements.txt and .env.example</done>
</task>

<task type="auto">
  <name>Task 2: Create config and predictor service</name>
  <files>
    backend/app/config.py
    backend/app/services/predictor.py
  </files>
  <action>
Create config.py using Pydantic Settings for environment configuration:
- CORS_ORIGINS: list[str] with default ["http://localhost:3000"]
- MODEL_DIR: str with default "app/models"
- Load from .env file

Create predictor.py adapted from cortex-data/predict_final.py:
- Module-level _models and _config dicts for storage
- load_models() function that loads:
  - cortex_model_global.pkl
  - cortex_model_Bardeaux.pkl
  - category_encoder_v3.pkl
  - cortex_config_v3.json
- unload_models() function that clears dicts
- predict() function with signature:
  predict(sqft: float, category: str, material_lines: int = 5,
          labor_lines: int = 2, has_subs: int = 0, complexity: int = 10) -> dict

IMPORTANT: Use Path(__file__).parent.parent / "models" for MODEL_DIR path.
The predict function should return dict with: estimate, range_low, range_high, model, confidence.
Round estimate values to 2 decimal places.

For category validation, use the mapping from cortex_config_v3.json. Note that Elastomere has accent (Elastomere with accent aigu on E).
  </action>
  <verify>
    python -c "from backend.app.config import settings; print(settings.cors_origins)"
    python -c "from backend.app.services.predictor import load_models, predict"
  </verify>
  <done>config.py exports settings, predictor.py exports load_models, unload_models, predict</done>
</task>

<task type="auto">
  <name>Task 3: Create main.py with lifespan and CORS</name>
  <files>
    backend/app/main.py
  </files>
  <action>
Create main.py with:

1. Lifespan context manager that calls load_models() on startup and unload_models() on shutdown
2. FastAPI app instance with:
   - title: "TOITURELV Cortex API"
   - description: "ML-powered roofing estimate API"
   - version: "1.0.0"
   - lifespan parameter

3. CORSMiddleware configuration:
   - allow_origins from settings.cors_origins
   - allow_credentials: True
   - allow_methods: ["GET", "POST"]
   - allow_headers: ["*"]

IMPORTANT: Add CORS middleware FIRST before any other middleware.

Do NOT include routers yet - those come in Plan 02.
  </action>
  <verify>
    python -c "from backend.app.main import app; print(app.title)"
  </verify>
  <done>main.py exports app with lifespan and CORS configured</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. All directories exist: backend/app/routers, backend/app/schemas, backend/app/services, backend/app/models
2. Python imports work without errors (run the verify commands)
3. Files contain expected exports
</verification>

<success_criteria>
- Backend directory structure matches file-type layout from research
- requirements.txt contains all dependencies for FastAPI ML serving
- config.py uses Pydantic Settings pattern
- predictor.py adapts predict_final.py logic correctly
- main.py has lifespan context manager and CORS middleware
- No import errors when testing modules
</success_criteria>

<output>
After completion, create `.planning/phases/01-fastapi-foundation/01-01-SUMMARY.md`
</output>
