# TOITURELV Cortex Backend - Environment Variables
# Copy this file to .env and fill in your values
#
# RAILWAY DEPLOYMENT NOTES:
# - Minimum memory: 512MB (without Pinecone)
# - With Pinecone: 2GB+ required (embedding model is ~500MB)
# - Trial plan (512MB max) cannot run Pinecone - omit those vars
# - Hobby plan ($5/mo) supports 2GB+ per service

# CORS Settings
# Comma-separated list of allowed origins for frontend requests
CORS_ORIGINS=["http://localhost:3000","https://toiture-main.vercel.app"]

# Model Settings
# Path to ML model files (relative to backend directory)
MODEL_DIR=app/models

# Pinecone Settings (CBR - Case-Based Reasoning)
# OPTIONAL - requires 2GB+ RAM for embedding model
# Omit these vars to disable CBR and save memory
# Get these from https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_HOST=your_index_host_url

# OpenRouter Settings (LLM Reasoning)
# Get API key from https://openrouter.ai/
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=openai/gpt-4o-mini

# Supabase Settings (Feedback System)
# Get these from https://supabase.com/dashboard/project/YOUR_PROJECT/settings/api
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key
